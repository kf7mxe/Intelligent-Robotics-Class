# Assignment 2
## Project organization
There are two ways to run the visual odemetry using two different python scripts. 
* visual_odemetry_live_camera_feed.py - This script runs the visual odemetry using the live camera feed from the webcam.
* visual_odemetry_from_live_camera_feed.py - This script runs the visual odemetry using a directory of images labeled frame0.png, frame1.png, frame2.png, etc.

To run just run the python scripts

The script monovideoodemetry_camera.py script is modified from the following repo https://github.com/alishobeiri/Monocular-Video-Odometery

raspbotControl.py script is used to control the raspbot using the keyboard. The following commands are used to control the raspbot:
* w - move forward
* s - move backward
* a - turn left
* d - turn right
* q - rotate 90 ccw
* e - rotate 90 cw
* c - stop move_circle


# Report 
## Findings:
Our findings showed that after driving in a ~1m circle, the Visual Odometry map showed dots configured in a long elliptical shape, with a lot of outlier points. This was quite different from the actual path followed by the robot. We are theorizing that certain variables in the environment affected the result of the odometry map such as hallways and the different lighting conditions. 

Image of the map generated by the visual odometry algorithm:
![map](/Assignment%202/map.png)

## Methodology:
We wrote code to drive the robot in a circle of about 1 meter. This helped maintain a relatively constant velocity instead of being jerky while stopping and starting. We used OpenCV to record images and generate a video, then used this repository for visual odometry: https://github.com/alishobeiri/Monocular-Video-Odometery.  We did modify it to handle pose or velocity to for the absolute scale as being constant since the robot was moving in a constant velocity and direction in a circle. 

## Challenges Faced:
During this assignment we faced several problems, many of which were related to getting things running on the raspbot hardware. We had trouble installing OpenCV on the Pi, and had to spend an entire day to get it working. Once it was working we ran into hardware limitations trying to process all the information onboard. We eventually decided on recording the video and processing it from a laptop. 


We faced another challenge where the video was being taken too fast and the images were being saved out of order, making the video jumpy. By slowing the image capture down we were able to get a smoother video and better odometry results. 

## Possible Improvements:
We could improve the accuracy of the map through additional calibration of the algorithm, a slower video, and testing in an environment with better lighting. Also if we could get a better pose and accuracy reading that would help the mapping accuracy significantly better.
